I"{<h2 id="zhixian-xie"><strong>Zhixian Xie</strong></h2>

<p style="margin-bottom:1.3cm; margin-left: 0.5cm"> </p>

<p>I am PhD student at <a href="https://asu-iris.github.io/">Intelligent Robotics and Interactive Systems (IRIS) Lab</a> at Arizona State University.</p>

<p>In 2022, I received my B.Eng degree in automation at Shanghai Jiao Tong University, Shanghai, China. I joined IRIS lab for PhD study in 2024.1,  working with <a href="https://wanxinjin.github.io/">Dr. Wanxin Jin</a>.</p>

<p style="margin-bottom:1.2cm; margin-left: 1.5cm"> </p>

<center>
    <a href="mailto:zxxie@asu.edu" target="_blank"> 
    <img src="assets/img/platform_icon/email.gif" width="35" target="_blank" /> </a>   &nbsp;&nbsp;&nbsp;
<!-- <a href = "https://scholar.google.com/citations?user=SoEC4h4AAAAJ&hl=en" target="_blank"> 
    <img src="assets/img/platform_icon/scholar.png" width="35" target="_blank"></a>   &nbsp;&nbsp;&nbsp; -->
<a href="https://github.com/Zhi-Xian-Xie" target="_blank">
    <img src="assets/img/platform_icon/github.gif" width="35" target="_blank" /></a> &nbsp;&nbsp;&nbsp;
<!-- <a href = "https://twitter.com/jinwanxin" target="_blank">
    <img src="assets/img/platform_icon/twitter.gif" width="35" target="_blank"></a>  &nbsp;&nbsp;&nbsp; -->
<!-- <a href = "https://www.youtube.com/channel/UCkMgzXIhi3BmWP7tAdeyoaA" target="_blank">
    <img src="assets/img/platform_icon/youtube.gif" width="35" target="_blank"></a>  &nbsp;&nbsp;&nbsp; -->

</center>

<p><br /></p>

<hr />

<center>
    <h4><strong>My Research</strong></h4>
</center>

<p style="margin-bottom:1.2cm; margin-left: 1.5cm"> </p>

<p>My research focuses on:</p>

<ul>
  <li>
    <p><strong>Robot Learning from Human:</strong>  We develop methods to empower a robot with the ability to efficiently understand and be understood by human users through a variety of physical interactions. We explore how robots can aptly respond to and collaborate meaningfully with users.</p>
  </li>
  <li>
    <p><strong>Dexterous Manipulation</strong> We develop model-based and model-free mathods to enable highly-dynamic, contact-rich tasks on robot manipulation tasks.</p>
  </li>
</ul>

<p style="margin-bottom:1.2cm; margin-left: 1.5cm"> </p>

<hr />

<center>
    <h4><strong>Publication &amp; Preprints</strong></h4>
</center>

<p style="margin-bottom:1.2cm; margin-left: 1.5cm"> </p>
<p><img src="collections/research/human/safe_alignment.gif" width="160" align="left" hspace="30" vspace="0" /></p>

<p><strong>Safe MPC Alignment with Human Directional Feedback</strong> <br />
<b>Zhixian Xie</b>, Wenlong Zhang, Yi Ren, Zhaoran Wang, George. J. Pappas and Wanxin Jin<br />
<em>Preprint, submitted to IEEE Transactions on Robotics (T-RO)</em> <br />
<a href="https://arxiv.org/abs/2407.04216" target="_blank">[PDF]</a>/ 
<a href="https://github.com/asu-iris/Safe-MPC-Alignment" target="_blank">[Code]</a>/
<a href="https://youtu.be/QOODShHLQJE" target="_blank">[Video]</a>/
<a href="https://zhi-xian-xie.github.io/safe_alignment_site/" target="_blank">[Webpage]</a></p>

<p style="margin-bottom:1.2cm; margin-left: 1.5cm"> </p>
<p><img src="collections/research/VLM/vlm.gif" width="160" align="left" hspace="30" vspace="20" /></p>

<p><strong>Language-Model-Assisted Bi-Level Programming for Reward Learning from Internet Videos</strong> <br />
Harsh Mahesheka, <b>Zhixian Xie</b>, Zhaoran Wang, Wanxin Jin <br />
<em>arXiv preprint, 2024</em> <br />
<a href="https://arxiv.org/abs/2410.09286" target="_blank">[PDF]</a>/ 
<a href="https://www.youtube.com/watch?v=CzlyYLu4mLQ" target="_blank">[Video]</a>/
<a href="https://harshmahesheka.github.io/vid-to-reward/" target="_blank">[Webpage]</a></p>

<p style="margin-bottom:1.2cm; margin-left: 1.5cm"> </p>
<p><img src="collections/research/human/cut_robust.png" width="160" align="left" hspace="30" vspace="20" /></p>

<p><strong>Robust Reward Alignment via Hypothesis Space Batch Cutting</strong> <br />
<b>Zhixian Xie</b>, Haode Zhang, Yizhe Feng, Wanxin Jin <br />
<em>Accepted by ICML 2025</em> <br />
<a href="https://arxiv.org/abs/2410.09286" target="_blank">[PDF]</a>/ 
Video: Coming Soon/
Code: Coming Soon/
Page: Coming Soon</p>
<p style="margin-bottom:1.2cm; margin-left: 1.5cm"> </p>

:ET